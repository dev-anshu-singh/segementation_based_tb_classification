{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":20797,"sourceType":"datasetVersion","datasetId":15700},{"sourceId":2332307,"sourceType":"datasetVersion","datasetId":891819},{"sourceId":4962811,"sourceType":"datasetVersion","datasetId":2878166},{"sourceId":11119559,"sourceType":"datasetVersion","datasetId":6933847},{"sourceId":280400,"sourceType":"modelInstanceVersion","modelInstanceId":240230,"modelId":261877}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom tensorflow.keras.models import load_model\nfrom keras.applications import DenseNet169\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\nimport os\nimport shutil\n\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:37:17.332227Z","iopub.execute_input":"2025-03-25T19:37:17.332537Z","iopub.status.idle":"2025-03-25T19:37:17.337260Z","shell.execute_reply.started":"2025-03-25T19:37:17.332514Z","shell.execute_reply":"2025-03-25T19:37:17.336406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"img_list and labels for pulmonary-chest-xray-abnormalities dataset","metadata":{}},{"cell_type":"code","source":"china_file_path = '/kaggle/input/pulmonary-chest-xray-abnormalities/ChinaSet_AllFiles/ChinaSet_AllFiles/CXR_png'\nmontgomery_file_path = '/kaggle/input/pulmonary-chest-xray-abnormalities/Montgomery/MontgomerySet/CXR_png'\n\nimg_list_test = []\nlabels_test = []\n\ndef create_img_label_list(file_path,img_list,labels):\n    for filename in sorted(os.listdir(file_path)):\n        label = filename.split('_')[-1][0]\n        img = cv2.imread(os.path.join(file_path,filename))\n\n        if img is None:\n            print(filename)\n            continue\n        \n        img = cv2.resize(img, (256,256))/255.0    #resizing and normalizing\n        img_list.append(img)\n        \n        if label=='1':\n            labels.append(1)\n        if label=='0':\n            labels.append(0)\n\ncreate_img_label_list(china_file_path,img_list_test,labels_test)\ncreate_img_label_list(montgomery_file_path,img_list_test,labels_test)\n\nimg_test_2 = np.array(img_list_test)\nlabels_test_2 = np.array(labels_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:37:20.087907Z","iopub.execute_input":"2025-03-25T19:37:20.088210Z","iopub.status.idle":"2025-03-25T19:38:48.058529Z","shell.execute_reply.started":"2025-03-25T19:37:20.088188Z","shell.execute_reply":"2025-03-25T19:38:48.057831Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"creating img_list and labels for tuberculosis-tb-chest-xray-dataset","metadata":{}},{"cell_type":"code","source":"# normal_img_path = '/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal'\n# tb_img_path = '/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis'\n\n# # img_list=[]\n# # labels = []\n\n# all_filenames = os.listdir(normal_img_path)\n# selected_filenames = random.sample(all_filenames, 700)\n\n# # Process selected images\n# for filename in selected_filenames:\n#     img = cv2.imread(os.path.join(normal_img_path, filename))\n#     img = cv2.resize(img, (256, 256)) / 255.0  # Normalize\n#     img_list.append(img)\n#     labels.append(0) \n\n# for filename in os.listdir(tb_img_path):\n#     img = cv2.imread(os.path.join(tb_img_path,filename))\n#     img = cv2.resize(img,(256,256))/255.0\n#     img_list.append(img)\n#     labels.append(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:38:48.064691Z","iopub.execute_input":"2025-03-25T19:38:48.065025Z","iopub.status.idle":"2025-03-25T19:38:48.083270Z","shell.execute_reply.started":"2025-03-25T19:38:48.064997Z","shell.execute_reply":"2025-03-25T19:38:48.082649Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"creating img_list and labels for tbx11k-simplified dataset","metadata":{}},{"cell_type":"code","source":"data_df = pd.read_csv('/kaggle/input/tbx11k-simplified/tbx11k-simplified/data.csv')\n\nactive_tb = data_df[data_df['tb_type']=='active_tb']['fname'].tolist()\nactive_tb = list(pd.unique(active_tb))\nnormal = data_df[data_df['image_type']=='healthy']['fname'].tolist()\n\nimg_path = '/kaggle/input/tbx11k-simplified/tbx11k-simplified/images'\n\nimg_list=[]\nlabels = []\n\nselected_normal = random.sample(normal, len(active_tb))\n\nprint(f\"shape of selected_normal: {len(selected_normal)}\")\nprint(f\"shape of active_tb: {len(active_tb)}\")\n\n# Process selected images\nfor filename in selected_normal:\n    img = cv2.imread(os.path.join(img_path, filename))\n    img = cv2.resize(img, (256, 256)) / 255.0  # Normalize\n    img_list.append(img)\n    labels.append(0) \n\nfor filename in active_tb:\n    img = cv2.imread(os.path.join(img_path,filename))\n    img = cv2.resize(img,(256,256))/255.0\n    img_list.append(img)\n    labels.append(1)\n\n\nimg_list = np.array(img_list)\nlabels = np.array(labels)\n\n# shuffle_indices = np.random.permutation(len(img_list))\n# img_list = img_list[shuffle_indices]\n# labels = labels[shuffle_indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:38:48.084580Z","iopub.execute_input":"2025-03-25T19:38:48.084875Z","iopub.status.idle":"2025-03-25T19:39:06.934630Z","shell.execute_reply.started":"2025-03-25T19:38:48.084855Z","shell.execute_reply":"2025-03-25T19:39:06.933956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, labels_train, labels_val = train_test_split(img_list,labels,test_size=0.2,random_state=42,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:39:06.959830Z","iopub.execute_input":"2025-03-25T19:39:06.960018Z","iopub.status.idle":"2025-03-25T19:39:08.788514Z","shell.execute_reply.started":"2025-03-25T19:39:06.960002Z","shell.execute_reply":"2025-03-25T19:39:08.787828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_val, X_test, labels_val, labels_test = train_test_split(X_val,labels_val,test_size=0.20,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:39:08.797359Z","iopub.execute_input":"2025-03-25T19:39:08.797651Z","iopub.status.idle":"2025-03-25T19:39:08.901217Z","shell.execute_reply.started":"2025-03-25T19:39:08.797622Z","shell.execute_reply":"2025-03-25T19:39:08.900499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def jaccard_index(y_true, y_pred, smooth=100):\n    y_true_f = tf.reshape(tf.cast(y_true, tf.float32), [-1])  # Flatten and cast ground truth\n    y_pred_f = tf.reshape(tf.cast(y_pred, tf.float32), [-1])  # Flatten and cast predictions\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)  # Compute intersection\n    total = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection  # Total pixels\n    return (intersection + smooth) / (total + smooth)\n\n\ndef dice_coefficient(y_true, y_pred, smooth=1):\n    y_true_f = tf.reshape(tf.cast(y_true, tf.float32), [-1])  # Flatten and cast y_true to float32\n    y_pred_f = tf.reshape(tf.cast(y_pred, tf.float32), [-1])  # Flatten and cast y_pred to float32\n    \n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    \n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\n\nsegment_model = load_model('/kaggle/input/segment_model/keras/default/1/best_model (1).keras', custom_objects = { 'dice_coefficient':dice_coefficient, 'jaccard_index':jaccard_index})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:43:14.093985Z","iopub.execute_input":"2025-03-25T18:43:14.094184Z","iopub.status.idle":"2025-03-25T18:43:19.224627Z","shell.execute_reply.started":"2025-03-25T18:43:14.094163Z","shell.execute_reply":"2025-03-25T18:43:19.223816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def segment_and_preprocess(img):\n    img_resized = np.expand_dims(img, axis=0)\n    \n    mask = segment_model.predict(img_resized,verbose=0)[0] \n    mask = (mask > 0.5).astype(np.float32) \n    \n    segmented_xray = img * mask\n    \n    return segmented_xray\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:43:19.225443Z","iopub.execute_input":"2025-03-25T18:43:19.225650Z","iopub.status.idle":"2025-03-25T18:43:19.229962Z","shell.execute_reply.started":"2025-03-25T18:43:19.225633Z","shell.execute_reply":"2025-03-25T18:43:19.229083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Apply segmentation and preprocessing with a progress bar\nX_train_preprocessed = np.array([segment_and_preprocess(img) for img in tqdm(X_train, desc=\"Processing Training Data\")])\nX_val_preprocessed = np.array([segment_and_preprocess(img) for img in tqdm(X_val, desc=\"Processing Validation Data\")])\nX_test_preprocessed = np.array([segment_and_preprocess(img) for img in tqdm(X_test, desc=\"Preprocessing Test Data\")])\n\n\nimg_test_2_preprocessed = np.array([segment_and_preprocess(img) for img in tqdm(img_test_2, desc=\"Processing Validation Data\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:39:08.996552Z","iopub.execute_input":"2025-03-25T19:39:08.996838Z","iopub.status.idle":"2025-03-25T19:42:01.917862Z","shell.execute_reply.started":"2025-03-25T19:39:08.996795Z","shell.execute_reply":"2025-03-25T19:42:01.917068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 16\n\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    # shear_range=0.1,\n    zoom_range=0.05,\n    horizontal_flip=True,\n    # vertical_flip=True,\n)\n\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n\ntrain_data = train_datagen.flow(\n    X_train_preprocessed,\n    labels_train,\n    batch_size=batch_size,\n    shuffle=True\n)\n\nval_data = val_datagen.flow(\n    X_val_preprocessed,\n    labels_val,\n    batch_size=batch_size,\n    shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:46:14.136906Z","iopub.execute_input":"2025-03-25T18:46:14.137139Z","iopub.status.idle":"2025-03-25T18:46:14.501885Z","shell.execute_reply.started":"2025-03-25T18:46:14.137120Z","shell.execute_reply":"2025-03-25T18:46:14.500936Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Testing our ImageDataGenerator","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef show_batch(data_generator, batch_size):\n    images, labels = next(data_generator)  \n    plt.figure(figsize=(12, 6))\n\n    for i in range(min(batch_size, 8)):  \n        plt.subplot(2, 4, i + 1)\n        plt.imshow(images[i], cmap=\"gray\")  \n        plt.title(f\"Label: {labels[i]}\")\n        plt.axis(\"off\")\n\n    plt.show()\n\nprint(\"Training Data Batch:\")\nshow_batch(train_data, batch_size)\n\nprint(\"Validation Data Batch:\")\nshow_batch(val_data, batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:46:14.502847Z","iopub.execute_input":"2025-03-25T18:46:14.503166Z","iopub.status.idle":"2025-03-25T18:46:15.876454Z","shell.execute_reply.started":"2025-03-25T18:46:14.503131Z","shell.execute_reply":"2025-03-25T18:46:15.875467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet169\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Concatenate, Input, BatchNormalization, GlobalAveragePooling2D, Dense, Flatten, Dropout, Conv2D, MaxPool2D,Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.metrics import AUC,Precision, Recall\n\nstrategy = tf.distribute.MirroredStrategy()\nprint(\"Number of GPUs:\", strategy.num_replicas_in_sync)\n\nwith strategy.scope():\n\n    densenet_base=DenseNet169(\n        weights=\"imagenet\",\n        include_top=False,\n        input_shape=(256,256,3)\n    )\n    densenet_base.trainable=False\n\n    for layer in densenet_base.layers[-10:]:  \n        layer.trainable = True\n    \n    inp = Input(shape = (256,256,3))\n    \n    densenet_feature=densenet_base(inp)\n\n    x = GlobalAveragePooling2D()(densenet_feature)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    x = BatchNormalization()(x)\n    x = Dense(32, activation='relu')(x)\n    x = Dropout(0.1)(x)\n    x = BatchNormalization()(x)\n    x = Dense(8, activation='relu')(x)\n    x = BatchNormalization()(x)\n    out = Dense(1,activation='sigmoid')(x)\n    \n    classification_model = Model(inputs = inp, outputs = out)\n\n    classification_model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss='binary_crossentropy',\n        metrics=['accuracy',Precision(name='precision'), Recall(name='recall')]\n    )\n\nclassification_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:49:23.973207Z","iopub.execute_input":"2025-03-25T18:49:23.973508Z","iopub.status.idle":"2025-03-25T18:49:28.025340Z","shell.execute_reply.started":"2025-03-25T18:49:23.973487Z","shell.execute_reply":"2025-03-25T18:49:28.024693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"best_model_2.keras\", monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1)\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1)\nlr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1)\n\nhistory = classification_model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=100,\n    callbacks=[checkpoint,lr_scheduler]\n)\n\n\nclassification_model.load_weights(\"best_model_2.keras\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:51:16.453414Z","iopub.execute_input":"2025-03-25T18:51:16.453780Z","iopub.status.idle":"2025-03-25T19:19:35.852126Z","shell.execute_reply.started":"2025-03-25T18:51:16.453755Z","shell.execute_reply":"2025-03-25T19:19:35.851184Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plotting accuracy and loss graph","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\n\n# Loss Plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss over Epochs')\nplt.legend()\n\n# Accuracy Plot (if your model has accuracy metric)\nif 'accuracy' in history.history:\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy over Epochs')\n    plt.legend()\n\nplt.tight_layout()\nplt.savefig(\"training_plot.png\", dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:28:24.387363Z","iopub.execute_input":"2025-03-25T19:28:24.387827Z","iopub.status.idle":"2025-03-25T19:28:25.501965Z","shell.execute_reply.started":"2025-03-25T19:28:24.387791Z","shell.execute_reply":"2025-03-25T19:28:25.501057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ny_true = labels_test\nX_test = X_test_preprocessed\n\ny_pred_probs = classification_model.predict(X_test) \ny_pred = (y_pred_probs > 0.5).astype(int) \n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Display classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred))\n\nplt.figure(figsize=(5, 4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No TB\", \"TB\"], yticklabels=[\"No TB\", \"TB\"])\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:42:43.913222Z","iopub.execute_input":"2025-03-25T19:42:43.913562Z","iopub.status.idle":"2025-03-25T19:42:47.297644Z","shell.execute_reply.started":"2025-03-25T19:42:43.913533Z","shell.execute_reply":"2025-03-25T19:42:47.296783Z"}},"outputs":[],"execution_count":null}]}